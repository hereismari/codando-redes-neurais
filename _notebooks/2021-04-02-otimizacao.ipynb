{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "random-graduation",
   "metadata": {},
   "source": [
    "# Algoritmos de Otimização"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expanded-legislature",
   "metadata": {},
   "source": [
    "No Deep Learning temos como propósito que nossas redes neurais aprendam a aproximar uma função de interesse, como o preço de casas numa regressão, ou a função que classifica objetos numa foto, no caso da classificação.\n",
    "\n",
    "Esse aprendizado se dá por meio da otimizição da rede neural para minimizar a função de custo, mas podemos usar vários algoritmos diferentes para alcançar esse mínimo. Já vimos anteriormente o gradiente descendente, mas como ele é muito importante e serve de base para os outros métodos, vamos começar recapitulando ele."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proper-belize",
   "metadata": {},
   "source": [
    "## Descida de Gradiente Estocástica (SGD)\n",
    "Na descida de gradiente estocástica separamos os nossos dados de treino em vários subconjuntos, que chamamos de mini-batches. No começo eles serão pequenos, como 32-128 exemplos, para aplicações mais avançadas eles tendem a ser muito maiores, na ordem de 1024 e até mesmo 8192 exemplos por mini-batch.\n",
    "\n",
    "Como na descida de gradiente padrão, computamos o gradiente da função de custo em relação aos exemplos, e subtraímos o gradiente vezes uma taxa de apredizado dos parâmetros da rede. Podemos ver o SGD como tomando um passo pequeno na direção de maior redução do valor da loss.\n",
    "\n",
    "### Equação\n",
    "$w_{t+1} = w_t - \\eta \\cdot \\nabla L$\n",
    "\n",
    "### Código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "tropical-attention",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "def sgd(weights, gradients, eta):\n",
    "    return jax.tree_util.tree_multimap(lambda w, g: w - eta*g, weights, gradients)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entire-shannon",
   "metadata": {},
   "source": [
    "# IMAGEM LEGAL DE SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cleared-charles",
   "metadata": {},
   "source": [
    "## Momentum\n",
    "Um problema com o uso de mini-batches é que agora estamos **estimando** a direção que diminui a função de perda no conjunto de treino, e quão menor o mini-batch mais ruidosa é a nossa estimativa. Para consertar esse problema do ruído nós introduzimos a noção de momentum. O momentm faz sua otimização agir como uma bola pesada descendo uma montanha, então mesmo que o caminho seja cheio de montes e buracos a direção da bola não é muito afetada. De um ponto de vista mais matemático as nossas atualizações dos pesos vão ser uma combinação entre os gradientes desse passo e os gradientes anteriores, estabilizando o treino.\n",
    "\n",
    "### Equação\n",
    "$v_{t} = \\gamma v_{t-1} + \\nabla L \\quad \\text{o gamma serve como um coeficiente ponderando entre usar os updates anteriores e o novo gradiente} \\\\\n",
    "w_{t+1} = w_t - \\eta v_t\n",
    "$\n",
    "\n",
    "### Código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "asian-statement",
   "metadata": {},
   "outputs": [],
   "source": [
    "def momentum(weights, gradients, eta, mom, gamma):\n",
    "    mom = jax.tree_util.tree_multimap(lambda v, g: gamma*v + g, weights, mom)\n",
    "    return jax.tree_util.tree_multimap(lambda w, v: w - eta*mom, weights, mom)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greatest-county",
   "metadata": {},
   "source": [
    "## RMSProp\n",
    "Criado por Geoffrey Hinton durante uma aula, esse método é o primeiro **método adaptivo** que estamos vendo. O que isso quer dizer é que o método tenta automaticamente computar uma taxa de aprendizado diferente para cada um dos pesos da nossa rede neural, usando taxas pequenas para parâmetros que sofrem atualização frequentemente e taxas maiores para parâmetros que são atualizados mais raramente, permitindo uma otimização mais rápida. \n",
    "\n",
    "Mais especificamente, o RMSProp divide o update normal do SGD pela raiz da soma dos quadrados dos gradientes anteriores (por isso seu nome Root-Mean-Square Proportional), assim reduzindo a magnitude da atualização de acordo com as magnitudes anteriores.\n",
    "\n",
    "### Equação\n",
    "$\n",
    "\\nu_{t} = \\gamma \\nu_{t-1} + (1 - \\gamma) (\\nabla L)^2 \\\\\n",
    "w_{t+1} = w_t - \\frac{\\eta \\nabla L}{\\sqrt{\\nu_t + \\epsilon}} \n",
    "$\n",
    "\n",
    "### Código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "responsible-estate",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computa_momento(updates, moments, decay, order):\n",
    "    return jax.tree_multimap(\n",
    "      lambda g, t: (1 - decay) * (g ** order) + decay * t, updates, moments)\n",
    "def rmsprop(updates, nu, gamma):\n",
    "    nu = computa_momento(updates, nu, gamma, 2)\n",
    "    updates = jax.tree_multimap(\n",
    "        lambda g, n: g * jax.lax.rsqrt(n + eps), updates, nu)\n",
    "    return updates, nu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "musical-dependence",
   "metadata": {},
   "source": [
    "## Adam\n",
    "Por fim o Adam usa ideias semelhantes ao Momentum e ao RMSProp, mantendo médias exponenciais tanto dos gradientes passados, quanto dos seus quadrados.\n",
    "\n",
    "### Equação\n",
    "$\n",
    "m_t = \\beta_1 m_{t-1} + (1 - \\beta_1) \\nabla L \\\\\n",
    "v_t = \\beta_2 v_{t-1} + (1 - \\beta_2) (\\nabla L)^2 \\\\\n",
    "w_{t+1} = w_t - \\frac{\\eta m_t}{\\sqrt{v_t} \\epsilon} \n",
    "$\n",
    "\n",
    "### Código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "devoted-franchise",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adam(updates, mu, nu, b1, b2):\n",
    "    mu = computa_momento(updates, mu, b1, 1)\n",
    "    nu = computa_momento(updates, nu, b2, 2)\n",
    "    updates = jax.tree_multimap(\n",
    "        lambda m, v: m / (jnp.sqrt(v + eps_root) + eps), mu, nu)\n",
    "    return updates, mu, nu"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
