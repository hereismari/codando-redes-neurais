{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dressed-indonesian",
   "metadata": {},
   "source": [
    "# Algoritmos de Otimização"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "retained-vault",
   "metadata": {},
   "source": [
    "No Deep Learning temos como propósito que nossas redes neurais aprendam a aproximar uma função de interesse, como o preço de casas numa regressão, ou a função que classifica objetos numa foto, no caso da classificação.\n",
    "\n",
    "Esse aprendizado se dá por meio da otimizição da rede neural para minimizar a função de custo, mas podemos usar vários algoritmos diferentes para alcançar esse mínimo. Já vimos anteriormente o gradiente descendente, mas como ele é muito importante e serve de base para os outros métodos, vamos começar recapitulando ele."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crazy-finland",
   "metadata": {},
   "source": [
    "## Descida de Gradiente Estocástica (SGD)\n",
    "Na descida de gradiente estocástica separamos os nossos dados de treino em vários subconjuntos, que chamamos de mini-batches. No começo eles serão pequenos, como 32-128 exemplos, para aplicações mais avançadas eles tendem a ser muito maiores, na ordem de 1024 e até mesmo 8192 exemplos por mini-batch.\n",
    "\n",
    "Como na descida de gradiente padrão, computamos o gradiente da função de custo em relação aos exemplos, e subtraímos o gradiente vezes uma taxa de apredizado dos parâmetros da rede. Podemos ver o SGD como tomando um passo pequeno na direção de maior redução do valor da loss.\n",
    "\n",
    "### Equação\n",
    "$w_{t+1} = w_t - \\eta \\cdot \\nabla L$\n",
    "\n",
    "### Código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "signed-community",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "def sgd(weights, gradients, eta):\n",
    "    return jax.tree_util.tree_multimap(lambda w, g: w - eta*g, weights, gradients)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "immune-cabin",
   "metadata": {},
   "source": [
    "# IMAGEM LEGAL DE SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "joint-residence",
   "metadata": {},
   "source": [
    "## Momentum\n",
    "Um problema com o uso de mini-batches é que agora estamos **estimando** a direção que diminui a função de perda no conjunto de treino, e quão menor o mini-batch mais ruidosa é a nossa estimativa. Para consertar esse problema do ruído nós introduzimos a noção de momentum. O momentm faz sua otimização agir como uma bola pesada descendo uma montanha, então mesmo que o caminho seja cheio de montes e buracos a direção da bola não é muito afetada. De um ponto de vista mais matemático as nossas atualizações dos pesos vão ser uma combinação entre os gradientes desse passo e os gradientes anteriores, estabilizando o treino.\n",
    "\n",
    "### Equação\n",
    "$v_{t} = \\gamma v_{t-1} + \\nabla L \\quad \\text{o gamma serve como um coeficiente ponderando entre usar os updates anteriores e o novo gradiente} \\\\\n",
    "w_{t+1} = w_t - \\eta v_t\n",
    "$\n",
    "\n",
    "### Código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proprietary-creature",
   "metadata": {},
   "outputs": [],
   "source": [
    "def momentum(weights, gradients, eta, v, gamma):\n",
    "    v = \n",
    "    return jax.tree_util.tree_multimap(lambda w, g: w - eta*g, weights, gradients)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
