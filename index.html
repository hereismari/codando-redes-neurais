---
layout: home
search_exclude: true
image: images/logo.png
---

## Motivação

Vários especialistas e pesquisadores experientes na área de Deep Learning apoiam a ideia de que a melhor forma de aprender os conceitos fundamentais de uma determinada área é **na prática**. Isto é, na medida que vamos sendo expostos a novos conceitos, implementá-los para de fato entendê-los.

> *De longe a melhor estratégia para aprender muito é reimplementar tudo... Quando eu leio algo me iludo achando que entendi, quando me forço a reimplementar sempre compreendo as coisas melhor. É meu jeito favorito de aprender.* - [Andrej Kaparthy, Diretor de IA da Tesla](https://www.quora.com/What-was-your-path-toward-ML-DL-What-books-did-you-enjoy-most-while-learning-DL)

> *Este material é a lista mais extensiva de implementações de machine learning do zero - isso é uma mina de ouro para quem gosta de aprender como eu gosto (construindo as coisas do zero): [https://t.co/LcoPAQBULv](https://t.co/LcoPAQBULv)* - [Trask (@iamtrask), Líder da OpenMined, Pesquisador na DeepMind](https://twitter.com/iamtrask/status/1034376270128267264?ref_src=twsrc%5Etfw)

Neste material iremos utilizar a abordagem de ensinar conceitos de Deep Learning **para programadoras(es)** da maneira que as coisas fiquem mais claras pra você: mostrando como as coisas funcionam, **programando do zero!**

## Sobre o curso

Aprender um conceito de maneira profunda (tun dun tisss) ainda é difícil e é uma tarefa que exige rigor e disciplina.

Os materiais disponíveis nesse site buscam apresentar conceitos básicos e avançados junto a implementações detalhadas e de fácil entendimento. Para tal não utilizaremos nenhum [framework de Deep Learning](https://www.youtube.com/watch?v=SJldOOs4vB8) apenas **Python**. O objetivo do curso não é transformar um programador(a) em um(a) *"Machine Learning enginneer"* mas sim um excelente material para quem quer entender o funcionamento destas técnicas nos mínimos detalhes.

Junto do código + explicação são apresentados sugestões de exercícios, blogs, artigos, vídeos.

[Quer apenas materiais?](bit.ly/awesome-dl)  
[Quer ir direto ao código?](https://github.com/mari-linhares/codando-deep-learning/tree/master/notebooks)

## Estrutura do curso

**Atenção: o curso é totalmente open source e colaborativo, tem sugestões? Quer ajudar? Chega mais!! Crie um issue/PR no repositório!**

---


Extras:

* [Glossário](https://mari-linhares.github.io/codando-deep-learning/notebooks/glossario.html)

---

0. Extra (Opcional)
    0.1 [Motivação: Introdução a Deep Learning](https://hereismari.github.io/codando-deep-learning-jax/2021/01/21/intro_a_deep_learning.html)  
    0.2 [História das Redes Neurais](https://hereismari.github.io/codando-deep-learning-jax/2021/01/21/historia_das_redes_neurais.html)  
    0.3 [Introdução a Numpy](https://hereismari.github.io/codando-deep-learning-jax/2021/01/21/intro_a_numpy.html)  

1. Introdução à Redes Neurais  
    1.1. [O que são ?](https://hereismari.github.io/codando-deep-learning-jax/2021/01/21/1.1.o_que_sao.html)  
    1.2. [Do que se alimentam ?](https://hereismari.github.io/codando-deep-learning-jax/2021/01/21//1.2.do_que_se_alimentam.html)  
    1.3. [Como aprendem ?](https://hereismari.github.io/codando-deep-learning-jax/2021/01/21/1.3.como_aprendem.html)  
    1.4. [Funções de ativação](https://hereismari.github.io/codando-deep-learning-jax/2021/01/21/1.4.funcoes_de_ativacao.html)   
    1.5. [Minha primeira Rede Neural <3](https://hereismari.github.io/codando-deep-learning-jax/2021/01/21/1.5.minha_primeira_rede_neural.html)  
    1.6. Minha primeira Rede Neural com JAX  
    1.7. Desafios e Exercicios  

2. Introdução a Redes Neurais com JAX  
    2.1. Introdução a JAX
    2.2. Algoritmos de otimização: SGD, Momentum, RMSprop, Adam  
    2.3. Inicialização dos pesos  
    2.4. Regularização e Dropout   
    2.5. Normalização: Batch norm, layer norm, group norm.  
    2.6. Data Augmentation  

3. Introdução a Redes Neurais Convolucionais com JAX
    3.1. O que são?  
    3.2. Implementação  
    3.3. Arquiteturas famosas  
                                                                                                                                              
4. Introdução à Redes Neurais Recorrentes com JAX   
    4.1. O que são?  
    4.2. RNN Simples e Vanish gradients  
    4.3. LSTM 
    4.4. Desafio: Implementar GRU
    
5. Introducao a Transformers com JAX  
    5.1. O que sao?  
    5.2. Attention  
    5.3. Arquitetura do Transformer  
    5.4. SoTA Transformers  
---

---

# Posts
